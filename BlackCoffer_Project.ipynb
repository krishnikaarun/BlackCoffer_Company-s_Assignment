{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9709c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
    "import re\n",
    "#nltk.download('punkt') #Run only once in a machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f357c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Input file\n",
    "os.chdir(r'C:\\Users\\krish\\DATA\\Blackcoffer_Assignment_Project') # Path - Input Excel file\n",
    "data = pd.read_csv(\"Input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee1a6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3      40  https://insights.blackcoffer.com/will-machine-...\n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be4c115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the column into list\n",
    "url = data[\"URL\"].tolist()\n",
    "url_id = data[\"URL_ID\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d461ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting the data from the URL (Website) using requests module and beautifulsoup module to take out only the text that is required\n",
    "os.chdir(r'C:\\Users\\krish\\DATA\\Blackcoffer_Assignment_Project\\Text_Files') # Path - A folder where all the text files with URL_ID\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "for i in range(len(url)):\n",
    "    # Creating the file name to save each URL's data into a text file\n",
    "    filename = str(url_id[i]) + '.txt'\n",
    "    r = requests.get(url[i],headers=headers)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    top = soup.title\n",
    "    top = top.string\n",
    "    top = top.removesuffix(\"- Blackcoffer Insights\")\n",
    "    bot = \"\"\n",
    "    elements = soup.find_all('p') \n",
    "    for element in elements:\n",
    "        bot = bot + element.text\n",
    "    file = open(filename,'w',encoding=\"utf-8\")\n",
    "    file.write(top + bot)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e622fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining and reading all the stopwords file from the folder and deleting the output file at end\n",
    "os.chdir(r'C:\\Users\\krish\\DATA\\Blackcoffer_Assignment_Project\\StopWords') # Path - The folder which contains all the StopWords\n",
    "my_files = glob.glob('*.txt') \n",
    " \n",
    "with open('output_file.txt','wb') as wfd: \n",
    "    for f in my_files: \n",
    "        with open(f,'rb') as fd: \n",
    "            shutil.copyfileobj(fd, wfd)\n",
    "file.close()\n",
    "\n",
    "file = open('output_file.txt','r')\n",
    "dat = file.read()\n",
    "file.close()\n",
    "dat = dat.split( )\n",
    "\n",
    "os.remove(\"output_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caab5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the URL's data into a single list\n",
    "text_op = []\n",
    "full_para_list = []\n",
    "os.chdir(r'C:\\Users\\krish\\DATA\\Blackcoffer_Assignment_Project\\Text_Files') # Path - The folder which has all the IRL_ID text files\n",
    "my_op = glob.glob('*.txt')\n",
    "    \n",
    "for i in my_op:\n",
    "    file = open(i,'r',encoding=\"utf8\")\n",
    "    full_para = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    full_para_list.append(full_para)\n",
    "    para = full_para.split()\n",
    "    resultwords  = [word for word in para if word.lower() not in dat]\n",
    "    result = ' '.join(resultwords)\n",
    "    text_op.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b9e5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing each text file's data and forming a combined list\n",
    "final = []\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "stopword_token = tokenizer.tokenize(str(dat))\n",
    "\n",
    "tempo = []\n",
    "for i in text_op:\n",
    "    words_token = tokenizer.tokenize(str(i))\n",
    "    tempo.append(words_token)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb85981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all the words in text files that are in the stopword list\n",
    "final = []\n",
    "count = 0\n",
    "for i in tempo:\n",
    "    words = []\n",
    "    for j in i:\n",
    "        if j not in dat:\n",
    "            words.append(j)\n",
    "    final.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89e5a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the positive and negative words into a list\n",
    "os.chdir(r'C:\\Users\\krish\\DATA\\Blackcoffer_Assignment_Project\\MasterDictionary') # Path - The folder which has positive and negative words file\n",
    "\n",
    "file = open('positive-words.txt','r')\n",
    "positive_words = file.read()\n",
    "file.close()\n",
    "positive_words = positive_words.split( )\n",
    "\n",
    "file = open('negative-words.txt','r')\n",
    "negative_words = file.read()\n",
    "file.close()\n",
    "negative_words = negative_words.split( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14f588d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the no of positive and negative words in each text file\n",
    "posi_list = []\n",
    "neg_list = []\n",
    "for i in final:\n",
    "    positive_len = 0\n",
    "    for j in i: \n",
    "        if j in positive_words:\n",
    "            positive_len = positive_len+1\n",
    "    posi_list.append(positive_len)\n",
    "    \n",
    "    negative_len = 0\n",
    "    for j in i: \n",
    "        if j in negative_words:\n",
    "            negative_len = negative_len+1\n",
    "    neg_list.append(negative_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "551b190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total no of text in the text files\n",
    "no_of_words = []\n",
    "for i in tempo:\n",
    "    no_of_words.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e4496a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding total no of sentence in the text files\n",
    "no_of_sentence= []\n",
    "for i in full_para_list:\n",
    "    number_of_sentences = sent_tokenize(i)\n",
    "    no_of_sentence.append(len(number_of_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe470d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the number of complex words in the text files\n",
    "def syllable(word):\n",
    "    word = word.lower()\n",
    "    count = 0\n",
    "    vowels = \"aeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith(\"e\"):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "no_of_complex_words_list = []\n",
    "syllable_list = []\n",
    "for w in tempo:\n",
    "    no_of_complex_words = 0\n",
    "    syllable_word_list = []\n",
    "    for x in w:\n",
    "        syllable_count = syllable(x)\n",
    "        if syllable_count > 1:\n",
    "            no_of_complex_words = no_of_complex_words + 1\n",
    "        syllable_word_list.append(syllable_count)\n",
    "    syllable_list.append(np.mean(syllable_word_list))\n",
    "    no_of_complex_words_list.append(no_of_complex_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e547a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the personal pronouns in the text files\n",
    "personal_pronouns = []\n",
    "for i in full_para_list:\n",
    "    pronounRegex = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)\n",
    "    pronouns = pronounRegex.findall(i)\n",
    "    personal_pronouns.append(len(pronouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecb4863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of character count in the text files\n",
    "char_count = []\n",
    "for i in full_para_list:\n",
    "    count = 0\n",
    "    for j in i: \n",
    "        for k in j:\n",
    "            if(k != ' '):\n",
    "                count = count + 1\n",
    "    char_count.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b4e57f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the gathered data into the dataframe\n",
    "data['POSITIVE_SCORE'] = posi_list\n",
    "data['NEGATIVE_SCORE'] = neg_list\n",
    "#Polarity Score = (Positive Score – Negative Score)/ ((Positive Score + Negative Score) + 0.000001)\n",
    "data['POLARITY_SCORE'] = (data[\"POSITIVE_SCORE\"] - data[\"NEGATIVE_SCORE\"]) / ((data[\"POSITIVE_SCORE\"] + data[\"NEGATIVE_SCORE\"]) + 0.000001)\n",
    "#Subjectivity Score = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)\n",
    "data['No_of_words'] = no_of_words\n",
    "data['SUBJECTIVITY_SCORE'] = (data[\"POSITIVE_SCORE\"] + data[\"NEGATIVE_SCORE\"]) / ((data['No_of_words']) + 0.000001)\n",
    "#Average Sentence Length = the number of words / the number of sentences\n",
    "data['No_of_sentence'] =  no_of_sentence\n",
    "data['AVG_SENTENCE_LENGTH'] = data[\"No_of_words\"] / data[\"No_of_sentence\"]\n",
    "data['No_of_complex_words'] = no_of_complex_words_list\n",
    "data['PERCENTAGE_OF_COMPLEX_WORDS'] = data[\"No_of_complex_words\"] / data[\"No_of_words\"]\n",
    "#Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
    "data['FOG_INDEX'] = (data['AVG_SENTENCE_LENGTH'] + data['PERCENTAGE_OF_COMPLEX_WORDS']) * 0.4\n",
    "#Average Number of Words Per Sentence = the total number of words / the total number of sentences\n",
    "data['AVG_NUMBER_OF_WORDS_PER_SENTENCE'] = data['No_of_words'] / data['No_of_sentence']\n",
    "data['COMPLEX_WORD_COUNT'] = data['No_of_complex_words']\n",
    "data['WORD_COUNT'] = data['No_of_words']\n",
    "data['SYLLABLE_PER_WORD'] = syllable_list\n",
    "data['PERSONAL_PRONOUNS'] = personal_pronouns\n",
    "#Sum of the total number of characters in each word/Total number of words\n",
    "data['char_count'] = char_count\n",
    "data['AVG_WORD_LENGTH'] = data['char_count'] / data['WORD_COUNT']\n",
    "\n",
    "data = data.drop(['No_of_words','No_of_sentence', 'No_of_complex_words', 'char_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0d7fb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE_SCORE</th>\n",
       "      <th>NEGATIVE_SCORE</th>\n",
       "      <th>POLARITY_SCORE</th>\n",
       "      <th>SUBJECTIVITY_SCORE</th>\n",
       "      <th>AVG_SENTENCE_LENGTH</th>\n",
       "      <th>PERCENTAGE_OF_COMPLEX_WORDS</th>\n",
       "      <th>FOG_INDEX</th>\n",
       "      <th>AVG_NUMBER_OF_WORDS_PER_SENTENCE</th>\n",
       "      <th>COMPLEX_WORD_COUNT</th>\n",
       "      <th>WORD_COUNT</th>\n",
       "      <th>SYLLABLE_PER_WORD</th>\n",
       "      <th>PERSONAL_PRONOUNS</th>\n",
       "      <th>AVG_WORD_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.034483</td>\n",
       "      <td>0.099828</td>\n",
       "      <td>16.138889</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>6.715797</td>\n",
       "      <td>16.138889</td>\n",
       "      <td>378</td>\n",
       "      <td>581</td>\n",
       "      <td>2.067126</td>\n",
       "      <td>3</td>\n",
       "      <td>9.327022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>-0.438596</td>\n",
       "      <td>0.055072</td>\n",
       "      <td>23.522727</td>\n",
       "      <td>0.683092</td>\n",
       "      <td>9.682328</td>\n",
       "      <td>23.522727</td>\n",
       "      <td>707</td>\n",
       "      <td>1035</td>\n",
       "      <td>2.193237</td>\n",
       "      <td>1</td>\n",
       "      <td>8.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.457627</td>\n",
       "      <td>0.111321</td>\n",
       "      <td>16.060606</td>\n",
       "      <td>0.671698</td>\n",
       "      <td>6.692922</td>\n",
       "      <td>16.060606</td>\n",
       "      <td>356</td>\n",
       "      <td>530</td>\n",
       "      <td>2.147170</td>\n",
       "      <td>5</td>\n",
       "      <td>9.335849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>-0.139241</td>\n",
       "      <td>0.134354</td>\n",
       "      <td>8.647059</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>3.720728</td>\n",
       "      <td>8.647059</td>\n",
       "      <td>385</td>\n",
       "      <td>588</td>\n",
       "      <td>2.112245</td>\n",
       "      <td>37</td>\n",
       "      <td>10.132653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.087751</td>\n",
       "      <td>18.233333</td>\n",
       "      <td>0.667276</td>\n",
       "      <td>7.560244</td>\n",
       "      <td>18.233333</td>\n",
       "      <td>365</td>\n",
       "      <td>547</td>\n",
       "      <td>2.199269</td>\n",
       "      <td>12</td>\n",
       "      <td>10.118830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112     149  https://insights.blackcoffer.com/business-anal...   \n",
       "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "     POSITIVE_SCORE  NEGATIVE_SCORE  POLARITY_SCORE  SUBJECTIVITY_SCORE  \\\n",
       "109              28              30       -0.034483            0.099828   \n",
       "110              16              41       -0.438596            0.055072   \n",
       "111              16              43       -0.457627            0.111321   \n",
       "112              34              45       -0.139241            0.134354   \n",
       "113              22              26       -0.083333            0.087751   \n",
       "\n",
       "     AVG_SENTENCE_LENGTH  PERCENTAGE_OF_COMPLEX_WORDS  FOG_INDEX  \\\n",
       "109            16.138889                     0.650602   6.715797   \n",
       "110            23.522727                     0.683092   9.682328   \n",
       "111            16.060606                     0.671698   6.692922   \n",
       "112             8.647059                     0.654762   3.720728   \n",
       "113            18.233333                     0.667276   7.560244   \n",
       "\n",
       "     AVG_NUMBER_OF_WORDS_PER_SENTENCE  COMPLEX_WORD_COUNT  WORD_COUNT  \\\n",
       "109                         16.138889                 378         581   \n",
       "110                         23.522727                 707        1035   \n",
       "111                         16.060606                 356         530   \n",
       "112                          8.647059                 385         588   \n",
       "113                         18.233333                 365         547   \n",
       "\n",
       "     SYLLABLE_PER_WORD  PERSONAL_PRONOUNS  AVG_WORD_LENGTH  \n",
       "109           2.067126                  3         9.327022  \n",
       "110           2.193237                  1         8.956522  \n",
       "111           2.147170                  5         9.335849  \n",
       "112           2.112245                 37        10.132653  \n",
       "113           2.199269                 12        10.118830  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b38ea86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the DataFrame into a Excel file\n",
    "os.chdir(r'C:\\Users\\krish\\DATA\\Blackcoffer_Assignment_Project') # Path - The output file will be stored\n",
    "data.to_excel(\"Output Data Structure.xlsx\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "603d71359ed1d9fe8529e0912945d40570428a0f34e43cffa7fe41267d475d48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
